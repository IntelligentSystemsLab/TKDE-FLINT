# FLKIT
Codes of the paper titled *FLKIT: A Federated Learning Mechanism Sharing Knowledge between Large and Compact Models for Intelligent IoT Services*

**Authors** : Shaoyuan Chen, Zihan Guo, Rui Liu, Linlin You

**Abstract** : A significant breakthrough has been achieved by large AI models (LMs). However, their adoption on edge devices in the Internet of Things (IoT) remains challenging, especially when both sensitive data is protected and computing power is limited to be used to update or run LMs directly. Even though federated learning (FL) can be applied to train lightweight models for IoT by orchestrating data-isolated and resource-restricted clients, it still requires a method that can transfer the knowledge encoded in LMs to local models running at various IoT clients. To address that, we propose a novel mechanism for FL in enabling knowledge sharing between cloud and edge in a privacy-preserving manner, called FLKIT. It implements a bi-directional knowledge distillation process between client-side compact models (CMs) and server-side LMs, through which, CMs carrying local knowledge are, first, aggregated to jointly fine-tune LMs, and then updated based on a meta-gradient distilled from the fine-tuned LMs to elevate their local performance. Experimental results show that FLKIT can be seamlessly integrated with general FL methods to improve their model training performance in terms of accuracy and speed by up to 31.6\% and 2.93$\times$, respectively. In addition, FLKIT is also adaptable to settings with different numbers of clients and degrees of data heterogeneity, making it a suitable solution for real-world intelligent services.
